{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the modules we're going to need\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import pandas as pd# Added\n",
    "from IPython.display import Audio\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We've previously preprocessed our data and coverted all files to a sample rate of 44100\n",
    "samplerate = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify where the audio files for training and testing reside\n",
    "train_folder = './../exp1/train'\n",
    "test_folder = './../exp1/test'\n",
    "\n",
    "# Get a list of all the training audio files (must be .WAV files)\n",
    "train_files = glob.glob(os.path.join(train_folder, '*.wav'))\n",
    "\n",
    "# Get a list of all the test audio files (must be .WAV files)\n",
    "test_files = glob.glob(os.path.join(test_folder, '*.wav'))\n",
    "\n",
    "# Specify the labels (classes) we're going to classify the data into\n",
    "label0 = 'abscent'\n",
    "label1 = 'present'\n",
    "labels = [label0, label1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make 1 second summarization as features with half second of hop length\n",
    "# 172 frames == 1 second (using 44100 samples per second)\n",
    "# 166 frames ~ 0.96 second\n",
    "feature_length = 96\n",
    "half_sec = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define lists to store the training features and corresponding training labels\n",
    "train_features = []\n",
    "train_labels = []\n",
    "\n",
    "# For every audio file in the training set, load the file, compute MFCCs, summarize them over time\n",
    "# using the mean and standard deviation (for each MFCC coefficient), and then save the features\n",
    "# and corresponding label in the designated lists\n",
    "for tf in train_files:\n",
    "    \n",
    "    print(\"filename: {:s}\".format(os.path.basename(tf)))\n",
    "    \n",
    "    # Load VGGish audio embeddings\n",
    "    vggish = pd.read_csv(tf[:-7]+\"VGGish_PCA.csv\",index_col=None, header=None)\n",
    "    vggish = pd.DataFrame.as_matrix(vggish)\n",
    "    \n",
    "    # Read labels for each frame\n",
    "    f0line = pd.read_csv(tf[:-7]+\"vocal.csv\",index_col=None, header=None)\n",
    "    f0line = pd.DataFrame.as_matrix(f0line)\n",
    "    f0line = f0line.T[0][48:] # VGGish starts from 0.48 second\n",
    "    \n",
    "    #print (vggish)\n",
    "    #print (mfcc.shape)\n",
    "    #print(\"number of chunks\", int(mfcc.shape[1]/half_sec))\n",
    "    \n",
    "    feature_vector = []\n",
    "    tf_label = []\n",
    "    \n",
    "    print (vggish.shape[0]/half_sec)\n",
    "    \n",
    "    for chunk in range(vggish.shape[0]): # if hop = 10ms then use: range(int(vggish.shape[0]/half_sec)):\n",
    "        start = chunk*half_sec\n",
    "        vggish_means = np.mean(vggish[start:start+1, :], 0) # I removed the smooth to get only one window\n",
    "        vggish_stddevs = np.std(vggish[start:start+1, :], 0)\n",
    "        #print (vggish_means.shape, start, start+feature_length)\n",
    "    \n",
    "        # Concatenate means and std. dev's into a single feature vector\n",
    "        #feature_vector.append(np.concatenate((vggish_means, vggish_stddevs), axis=0))\n",
    "        #print (np.concatenate((vggish_means, vggish_stddevs), axis=0))\n",
    "        #if hop = 10ms then use:feature_vector.append(vggish[start, :][0])\n",
    "        feature_vector.append(vggish[chunk, :])\n",
    "   \n",
    "        # Adjust labels to our classes\n",
    "        if len([x for x in f0line[start:start+feature_length] if x > 0]) >= half_sec: # 50%\n",
    "            tf_label.append('present')\n",
    "        else:\n",
    "            tf_label.append('abscent')\n",
    "\n",
    "    # Get labels index\n",
    "    tf_label_ind = [labels.index(lbl) for lbl in tf_label]\n",
    "    print(\"file label size: {:d}\".format(len(tf_label_ind)))\n",
    "    \n",
    "    # Store the feature vector and corresponding label in integer format\n",
    "    for idx in range(len(feature_vector)):\n",
    "        train_features.append(feature_vector[idx])\n",
    "        train_labels.append(tf_label_ind[idx]) \n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: MusicDelta_Country2_MIX.wav\n",
      "35\n",
      "file label size: (35,)\n",
      " \n",
      "filename: MusicDelta_Country1_MIX.wav\n",
      "71\n",
      "file label size: (71,)\n",
      " \n",
      "filename: SweetLights_YouLetMeDown_MIX.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/lib/python3/dist-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/usr/lib/python3/dist-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/usr/lib/python3/dist-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/usr/lib/python3/dist-packages/numpy/core/_methods.py:125: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815\n",
      "file label size: (815,)\n",
      " \n",
      "filename: MusicDelta_Gospel_MIX.wav\n",
      "156\n",
      "file label size: (156,)\n",
      " \n",
      "filename: PortStWillow_StayEven_MIX.wav\n",
      "659\n",
      "file label size: (659,)\n",
      " \n",
      "filename: StrandOfOaks_Spacestation_MIX.wav\n",
      "507\n",
      "file label size: (507,)\n",
      " \n",
      "filename: MusicDelta_Rock_MIX.wav\n",
      "26\n",
      "file label size: (26,)\n",
      " \n",
      "filename: InvisibleFamiliars_DisturbingWildlife_MIX.wav\n",
      "454\n",
      "file label size: (454,)\n",
      " \n",
      "filename: Snowmine_Curfews_MIX.wav\n",
      "572\n",
      "file label size: (572,)\n",
      " \n",
      "filename: CelestialShore_DieForUs_MIX.wav\n",
      "579\n",
      "file label size: (579,)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Define lists to store the test features and corresponding test labels\n",
    "test_features = []\n",
    "test_labels = []\n",
    "\n",
    "# For every audio file in the training set, load the file, compute MFCCs, summarize them over time\n",
    "# using the mean and standard deviation (for each MFCC coefficient), and then save the features\n",
    "# and corresponding label in the designated lists\n",
    "for tf in test_files:\n",
    "    \n",
    "    print(\"filename: {:s}\".format(os.path.basename(tf)))\n",
    "    \n",
    "    # Load VGGish audio embeddings\n",
    "    vggish = pd.read_csv(tf[:-7]+\"VGGish_PCA.csv\",index_col=None, header=None)\n",
    "    vggish = pd.DataFrame.as_matrix(vggish)\n",
    "    \n",
    "    # Read labels for each frame\n",
    "    f0line = pd.read_csv(tf[:-7]+\"vocal.csv\",index_col=None, header=None)\n",
    "    f0line = pd.DataFrame.as_matrix(f0line)\n",
    "    f0line = f0line.T[0][48:] # VGGish starts from 0\n",
    "    \n",
    "    #print (mfcc.shape)\n",
    "    #print(\"number of chunks\", int(mfcc.shape[1]/half_sec))\n",
    "    \n",
    "    feature_vector = []\n",
    "    tf_label = []\n",
    "    \n",
    "    print (vggish.shape[0])\n",
    "    \n",
    "    for chunk in range(vggish.shape[0]): # if hop = 10ms then use: range(int(vggish.shape[0]/half_sec)):\n",
    "        start = chunk*half_sec\n",
    "        vggish_means = np.mean(vggish[start:start+1, :], 0) # I removed the smooth to get only one window\n",
    "        vggish_stddevs = np.std(vggish[start:start+1, :], 0)\n",
    "        #print (vggish_means.shape, start, start+feature_length)\n",
    "    \n",
    "        # Concatenate means and std. dev's into a single feature vector\n",
    "        #feature_vector.append(np.concatenate((vggish_means, vggish_stddevs), axis=0))\n",
    "        #if hop = 10ms then use:feature_vector.append(vggish[start, :][0])\n",
    "        feature_vector.append(vggish[chunk, :])\n",
    "        \n",
    "        #print(feature_vector)\n",
    "        \n",
    "        # Adjust labels to our classes\n",
    "        if len([x for x in f0line[start:start+feature_length] if x > 0]) >= half_sec: # 50%\n",
    "            tf_label.append('present')\n",
    "        else:\n",
    "            tf_label.append('abscent')\n",
    "    \n",
    "    #Get labels index\n",
    "    tf_label_ind = np.array([labels.index(lbl) for lbl in tf_label])\n",
    "    print(\"file label size: {}\".format(tf_label_ind.shape))\n",
    "    \n",
    "    \n",
    "    # Store the feature vector and corresponding label in integer format\n",
    "    for idx in range(len(feature_vector)):\n",
    "        test_features.append(feature_vector[idx])\n",
    "        test_labels.append(tf_label_ind[idx])\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a scale object\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "# Learn the parameters from the training data only\n",
    "scaler.fit(train_features)\n",
    "\n",
    "# Apply the learned parameters to the training and test sets:\n",
    "train_features_scaled = scaler.transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "# Note, the first 2 operations (learning the standardization parameters from the training data \n",
    "# and applying them to the the training data) can be performed in one line using:\n",
    "# train_features_scaled = scaler.fit_transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_VGGish.sav']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the scaler to disk\n",
    "filename = 'scaler_VGGish.sav'\n",
    "joblib.dump(scaler, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Step 3: model training</h2>\n",
    "\n",
    "Now that all of our features are computed, we can train a clasification model! In this example we're going to use the following model: the support vector machine classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalized_model_SVM_100_VGGish.sav\n",
      "0.865625508378\n",
      "finalized_model_SVM_10_VGGish.sav\n",
      "0.879128029933\n",
      "finalized_model_SVM_1_VGGish.sav\n",
      "0.889702293802\n",
      "finalized_model_SVM_0.1_VGGish.sav\n",
      "0.891329103628\n",
      "finalized_model_SVM_0.01_VGGish.sav\n",
      "0.868553766065\n",
      "finalized_model_SVM_0.001_VGGish.sav\n",
      "0.687815194404\n",
      "finalized_model_SVM_0.0001_VGGish.sav\n",
      "0.687815194404\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to train a model with the training features we've extracted\n",
    "\n",
    "# Lets use a SVC with folowing C parameters: \n",
    "params = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "for c in params:\n",
    "    clf = sklearn.svm.SVC(C=c)\n",
    "\n",
    "    # Fit (=train) the model\n",
    "    clf.fit(train_features_scaled, train_labels)\n",
    "    \n",
    "    # save the model to disk\n",
    "    filename = 'finalized_model_SVM_'+str(c)+'_VGGish.sav'\n",
    "    print (filename)\n",
    "    joblib.dump(clf, filename)\n",
    "    \n",
    "    # Now lets predict the labels of the test data!\n",
    "    predictions = clf.predict(test_features_scaled)\n",
    "    \n",
    "    # We can use sklearn to compute the accuracy score\n",
    "    accuracy = sklearn.metrics.accuracy_score(test_labels, predictions)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use scikit-learn to train a model with the training features we've extracted\n",
    "\n",
    "# Lets use a SVC with default parameters: kernel RBF \n",
    "clf = sklearn.svm.SVC()\n",
    "\n",
    "# Fit (=train) the model\n",
    "clf.fit(train_features_scaled, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finalized_model_VGGish.sav']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to disk\n",
    "filename = 'finalized_model_SVM_'+c+'_VGGish.sav'\n",
    "joblib.dump(clf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now lets predict the labels of the test data!\n",
    "predictions = clf.predict(test_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.889702293802\n"
     ]
    }
   ],
   "source": [
    "# We can use sklearn to compute the accuracy score\n",
    "accuracy = sklearn.metrics.accuracy_score(test_labels, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687815194404\n"
     ]
    }
   ],
   "source": [
    "# We can use sklearn to compute the accuracy score BEFORE\n",
    "ones = np.ones(len(predictions))\n",
    "accuracy = sklearn.metrics.accuracy_score(test_labels, ones)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1568  351]\n",
      " [ 327 3901]]\n"
     ]
    }
   ],
   "source": [
    "# lets compute the show the confusion matrix:\n",
    "cm = sklearn.metrics.confusion_matrix(test_labels, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAScAAAEKCAYAAABQaJOpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb0b2dd2780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(cm, interpolation='nearest', cmap='gray')\n",
    "for i, line in enumerate(cm):\n",
    "    for j, l in enumerate(line):\n",
    "        ax.text(j, i, l, size=20, color='green')\n",
    "ax.set_xticks(range(len(cm)))\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticks(range(len(cm)))\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_ylabel('True label')\n",
    "ax.set_xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier without scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalized_model_RF_100_VGGish.sav\n",
      "0.884984545307\n",
      "finalized_model_RF_200_VGGish.sav\n",
      "0.884008459411\n",
      "finalized_model_RF_500_VGGish.sav\n",
      "0.883357735481\n",
      "finalized_model_RF_1000_VGGish.sav\n",
      "0.88709939808\n"
     ]
    }
   ],
   "source": [
    "params = [100, 200, 500, 1000]\n",
    "\n",
    "for estimators in params:\n",
    "    clf3 = RandomForestClassifier(n_estimators=estimators)\n",
    "\n",
    "    # Fit (=train) the model\n",
    "    clf3.fit(train_features, train_labels)\n",
    "    \n",
    "    # save the model to disk\n",
    "    filename = 'finalized_model_RF_'+str(estimators)+'_VGGish.sav'\n",
    "    print (filename)\n",
    "    joblib.dump(clf3, filename)\n",
    "    \n",
    "    # Now lets predict the labels of the test data!\n",
    "    predictions = clf3.predict(test_features)\n",
    "    # We can use sklearn to compute the accuracy score\n",
    "    accuracy = sklearn.metrics.accuracy_score(test_labels, predictions)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf3 = RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "# Fit (=train) the model\n",
    "clf3.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 4: model evaluation Random Forest Classifier (testing)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now lets predict the labels of the test data!\n",
    "predictions = clf3.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model accuracy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.885472588254\n"
     ]
    }
   ],
   "source": [
    "# We can use sklearn to compute the accuracy score\n",
    "accuracy = sklearn.metrics.accuracy_score(test_labels, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Confusion matrix</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets compute the show the confusion matrix:\n",
    "cm = sklearn.metrics.confusion_matrix(test_labels, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(cm, interpolation='nearest', cmap='gray')\n",
    "for i, line in enumerate(cm):\n",
    "    for j, l in enumerate(line):\n",
    "        ax.text(j, i, l, size=20, color='green')\n",
    "ax.set_xticks(range(len(cm)))\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticks(range(len(cm)))\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_ylabel('True label')\n",
    "ax.set_xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print (test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834796076407\n"
     ]
    }
   ],
   "source": [
    "# Load scaler (SVM)\n",
    "filename = '../scaler_VGGish.sav' \n",
    "# load the model from disk\n",
    "scaler = joblib.load(filename)\n",
    "\n",
    "# Transform data\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "# Load trained model (SVM)\n",
    "filename = '../finalized_model_SVM_0.1_VGGish.sav' \n",
    "# load the model from disk\n",
    "clf = joblib.load(filename)\n",
    "\n",
    "# Now lets predict the labels of the test data!\n",
    "predictions = clf.predict(test_features_scaled)\n",
    "\n",
    "# We can use sklearn to compute the accuracy score\n",
    "accuracy = sklearn.metrics.accuracy_score(test_labels, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.830407847186\n"
     ]
    }
   ],
   "source": [
    "# Load trained model (RF)\n",
    "filename = 'finalized_model_RF_1000_VGGish.sav' \n",
    "# load the model from disk\n",
    "clf3 = joblib.load(filename)\n",
    "\n",
    "# Now lets predict the labels of the test data!\n",
    "predictions = clf3.predict(test_features)\n",
    "# We can use sklearn to compute the accuracy score\n",
    "accuracy = sklearn.metrics.accuracy_score(test_labels, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715023231802\n"
     ]
    }
   ],
   "source": [
    "# Now lets predict the labels of the test data!\n",
    "ones = np.ones(len(predictions))\n",
    "# We can use sklearn to compute the accuracy score\n",
    "accuracy = sklearn.metrics.accuracy_score(test_labels, ones)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
