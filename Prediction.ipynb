{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the modules we're going to need\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import pandas as pd# Added\n",
    "from IPython.display import Audio\n",
    "from sklearn.externals import joblib\n",
    "import mir_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We've previously preprocessed our data and coverted all files to a sample rate of 44100\n",
    "samplerate = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify where the audio files for training and testing reside\n",
    "train_folder = './mir_class_train'\n",
    "test_folder = './mir_class_test'\n",
    "\n",
    "# Get a list of all the training audio files (must be .WAV files)\n",
    "train_files = glob.glob(os.path.join(train_folder, '*.wav'))\n",
    "\n",
    "# Get a list of all the test audio files (must be .WAV files)\n",
    "test_files = glob.glob(os.path.join(test_folder, '*.wav'))\n",
    "\n",
    "# Specify the labels (classes) we're going to classify the data into\n",
    "label0 = 'abscent'\n",
    "label1 = 'present'\n",
    "labels = [label0, label1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_size = 2048\n",
    "hop_size = 512\n",
    "n_bands = 40\n",
    "n_mfcc = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some time later...\n",
    "filename = 'finalized_model.sav' \n",
    "# load the model from disk\n",
    "clf = joblib.load(filename)\n",
    "\n",
    "filename = 'scaler.sav' \n",
    "# load the model from disk\n",
    "scaler = joblib.load(filename)\n",
    "#result = loaded_model.score(X_test, Y_test)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: MusicDelta_Rockabilly_MIX.wav\n",
      "mfcc matrix shape: (13, 2236)\n",
      "feature vector shape: (2236, 13)\n",
      "file label size: (4472,)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Test file name\n",
    "tf = \"./mir_class_test/MusicDelta_Rockabilly_MIX.wav\"\n",
    "\n",
    "test_feat =[]\n",
    "test_labels = []\n",
    "print(\"filename: {:s}\".format(os.path.basename(tf)))\n",
    "    \n",
    "# Load audio\n",
    "audio, sr = librosa.load(tf, sr=samplerate, mono=True)\n",
    "\n",
    "# Extract mfcc coefficients (remember we will discard the first one)\n",
    "# To see all the relevant kwarg arugments consult the documentation for\n",
    "# librosa.feature.mfcc, librosa.feature.melspectrogram and librosa.filters.mel\n",
    "mfcc = librosa.feature.mfcc(audio, sr=sr, n_fft=window_size, hop_length=hop_size,\n",
    "                            fmax=samplerate/2, n_mels=n_bands, n_mfcc=(n_mfcc + 1))\n",
    "          \n",
    "# Discard the first coefficient\n",
    "mfcc = mfcc[1:,:]\n",
    "print(\"mfcc matrix shape: {}\".format(mfcc.shape))\n",
    "    \n",
    "    \n",
    "# Calculate the feature vectors: transpose to make each mfcc vector as one sample\n",
    "feature_vector = mfcc.transpose()\n",
    "print(\"feature vector shape: {}\".format(feature_vector.shape))\n",
    "    \n",
    "# Read labels for each frame\n",
    "d2 = pd.read_csv(tf[:-7]+\"MELODY1.csv\",index_col=None, header=None)\n",
    "d2 = pd.DataFrame.as_matrix(d2)[:,1]\n",
    "# Adjust labels to our classes\n",
    "tf_label = ['present' if x > 0 else 'abscent' for x in d2]+['abscent']\n",
    "    \n",
    "#Get labels index\n",
    "tf_label_ind = np.array([labels.index(lbl) for lbl in tf_label])\n",
    "print(\"file label size: {}\".format(tf_label_ind.shape))\n",
    "    \n",
    "    \n",
    "# Store the feature vector and corresponding label in integer format\n",
    "for idx in range(len(feature_vector)-1):\n",
    "    test_feat.append(feature_vector[idx])\n",
    "    test_labels.append(tf_label_ind[idx*2])\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_scaled = scaler.transform(test_feat)\n",
    "output = clf.predict(feat_scaled)\n",
    "labels = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "output = np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 0.5858395989974937 False Alarme 0.13145539906103287\n"
     ]
    }
   ],
   "source": [
    "R, FA = mir_eval.melody.voicing_measures(labels, output)\n",
    "print (\"Recall\", R, \"False Alarme\", FA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:    0.9175662414131501\n",
      "Recall:       0.5858395989974937\n",
      "F-measure:    0.7151051625239006\n",
      "Voicing False Alarm Rate:  0.13145539906103287\n",
      "Voicing Recall Rate:       0.5858395989974937\n",
      "Overall Accuracy:          0.6666666666666666\n",
      "[935.0, 84.0, 661.0, 555]\n"
     ]
    }
   ],
   "source": [
    "import vad_cls\n",
    "\n",
    "# EVALUATE\n",
    "evaluation = vad_cls.evaluate_results(labels, output)\n",
    "print (evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
